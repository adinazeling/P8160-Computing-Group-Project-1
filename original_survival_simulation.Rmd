---
title: "Survival Analysis Simulation Study"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(survival)
```

Create a function that will create a dataset from a specific baseline hazard function

```{r}

# N = sample size    
# lambda = scale parameter in exponential, weibull, "cox" (> 0)
# gamma = shape parameter in weibull (> 0)
# alpha = shape parameter in "cox" (-inf to inf)
# beta = fixed treatment effect parameter
set.seed(123123)

generate_data = function(N, beta, distribution, lambda, gamma, alpha) {
  
  #Inverse survival function from baseline hazard functions to obtain event times
  exponential = function(u, x, lambda, beta) {
    time = -log(u) / (exp(x * beta) * lambda) }
  
  weibull = function(u, x, lambda, gamma, beta) {
    time = ( -log(u) / (exp(x * beta) * lambda) ) ^ (1 / gamma) }
  
  cox = function(u, x, lambda, alpha, beta) {
    time = (1/alpha) * log( 1 - (alpha * log(u) / (lambda * exp(beta * x))) ) }
  
  #treatment assignment
  x = 1 * (runif(N) < 0.5)

  #generate event times
  u = runif(N)
  
  if (distribution == "exponential") {
    time = exponential(u, x, lambda, beta) } 
  else if (distribution == "weibull") {
    time = weibull(u, x, lambda, gamma, beta) }
  else { 
    time = cox(u, x, lambda, alpha, beta) } 
  
  #censoring time
  C = rexp(N, lambda)

  # follow-up times and event indicators
  observed_time = pmin(time, C)
  status = 1 * (time <= C)

  # data set
  survival_data = data.frame(id = 1:N,
                             time = time,
                             observed_time = observed_time,
                             status = status,
                             x = x)
}
```

Function to run model then obtain performance measures

```{r}

obtain_performance = function(baseline_hazard, censor) {
  
  size_vector = c(100, 200, 300, 350, 400, 450, 500)
  sim = 1000

  exp_bias = rep(NA, length(size_vector))
  weibull_bias = rep(NA, length(size_vector))
  cox_bias = rep(NA, length(size_vector))

  exp_MSE = rep(NA, length(size_vector))
  weibull_MSE = rep(NA, length(size_vector))
  cox_MSE = rep(NA, length(size_vector))

  index = 0
  for (sample_size in size_vector){
  
    index = index + 1
  
    exp_beta = rep(NA, sim)
    weibull_beta = rep(NA, sim)
    cox_beta = rep(NA, sim)
  
    for (i in 1:sim) {
      data = generate_data(N = sample_size, beta = 3, distribution = baseline_hazard, lambda = 0.1,
                           gamma = 4, alpha = 4)
      # Fit three survival distributions
      if (censor == FALSE){
        fit.exponential = survreg(Surv(data$time) ~ data$x, dist = "exponential") 
        fit.weibull = survreg(Surv(data$time) ~ data$x, dist = "weibull")
        fit.cox = coxph(Surv(data$time) ~ data$x) 
        }
      else {
        fit.exponential = survreg(Surv(data$observed_time, data$status) ~ data$x, dist = "exponential") 
        fit.weibull = survreg(Surv(data$observed_time, data$status) ~ data$x, dist = "weibull")
        fit.cox = coxph(Surv(data$time, data$status) ~ data$x)
        }
      
      # Save beta coefficients 
      exp_beta[i] = -fit.exponential$coefficients[-1]
      weibull_beta[i] = -fit.weibull$coefficients[-1] / fit.weibull$scale
      cox_beta[i] = fit.cox$coefficients[1]
      
      }
  
    exp_bias[index] = (sum(exp_beta - beta)) / sim 
    weibull_bias[index] = (sum(weibull_beta - beta)) / sim
    cox_bias[index] = (sum(cox_beta - beta)) / sim
  
    exp_MSE[index] = (sum((beta - exp_beta)^2)) / sim
    weibull_MSE[index] = (sum((beta - weibull_beta)^2)) / sim
    cox_MSE[index] = (sum((beta - cox_beta)^2)) / sim
    
    }
  
  performance = data_frame(size_vector, exp_bias, weibull_bias, cox_bias,
                      exp_MSE, weibull_MSE, cox_MSE)
  
  }
```

Scenario 1: Exponential baseline hazard

```{r}

#uncensored
uncens_performance = obtain_performance(baseline_hazard = "exponential", censor = "FALSE")

min_bias = min(uncens_performance$exp_bias, uncens_performance$weibull_bias, uncens_performance$cox_bias)
max_bias = max(uncens_performance$exp_bias, uncens_performance$weibull_bias, uncens_performance$cox_bias)

plot(uncens_performance$exp_bias, ylim = c(min_bias, max_bias), main = "Sample size vs. Bias without Censoring")
lines(uncens_performance$cox_bias, col = "red")
lines(uncens_performance$weibull_bias, col = "blue")

min_MSE = min(uncens_performance$exp_MSE, uncens_performance$weibull_MSE, uncens_performance$cox_MSE)
max_MSE = max(uncens_performance$exp_MSE, uncens_performance$weibull_MSE, uncens_performance$cox_MSE)

plot(uncens_erformance$exp_MSE, ylim = c(min_MSE, max_MSE), main = "Sample size vs. MSE without Censoring")
lines(uncens_performance$cox_MSE, col = "red")
lines(uncens_performance$weibull_MSE, col = "blue")

################################################

#censored
cens_performance = obtain_performance(baseline_hazard = "exponential", censor = "TRUE")

min_bias = min(cens_performance$exp_bias, cens_performance$weibull_bias, cens_performance$cox_bias)
max_bias = max(cens_performance$exp_bias, cens_performance$weibull_bias, cens_performance$cox_bias)

plot(cens_performance$exp_bias, ylim = c(min_bias, max_bias), main = "Sample size vs. Bias with Censoring")
lines(cens_performance$cox_bias, col = "red")
lines(cens_performance$weibull_bias, col = "blue")

min_MSE = min(cens_performance$exp_MSE, cens_performance$weibull_MSE, cens_performance$cox_MSE)
max_MSE = max(cens_performance$exp_MSE, cens_performance$weibull_MSE, cens_performance$cox_MSE)

plot(cens_performance$exp_MSE, ylim = c(min_MSE, max_MSE), main = "Sample size vs. MSE with Censoring")
lines(cens_performance$cox_MSE, col = "red")
lines(cens_performance$weibull_MSE, col = "blue")

```

